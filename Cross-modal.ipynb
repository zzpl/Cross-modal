{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入需要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from scipy.io import loadmat, savemat\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import scipy.spatial\n",
    "import torchvision\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建图像、文本子网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNN(nn.Module):                                              \n",
    "    def __init__(self, input_dim=4096, output_dim=1024):\n",
    "        super(ImageNN, self).__init__()\n",
    "        self.denseL1 = nn.Linear(input_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.denseL1(x))\n",
    "        return out\n",
    "\n",
    "\n",
    "class TextNN(nn.Module):                                             \n",
    "    def __init__(self, input_dim=300, output_dim=1024):\n",
    "        super(TextNN, self).__init__()\n",
    "        self.denseL1 = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.denseL1(x))\n",
    "        return out\n",
    "\n",
    "\n",
    "class IDCM_NN(nn.Module):                                                    \n",
    "    def __init__(self, img_input_dim=4096, img_output_dim=2048,\n",
    "                 text_input_dim=1024, text_output_dim=2048, minus_one_dim=1024, output_dim=20):\n",
    "        super(IDCM_NN, self).__init__()\n",
    "        self.img_net = ImageNN(img_input_dim, img_output_dim)\n",
    "        self.text_net = TextNN(text_input_dim, text_output_dim)\n",
    "        self.linearLayer = nn.Linear(img_output_dim, minus_one_dim)\n",
    "        self.linearLayer1 = nn.Linear(text_output_dim, minus_one_dim)\n",
    "        self.linearLayer2 = nn.Linear(minus_one_dim, output_dim)\n",
    "\n",
    "\n",
    "    def forward(self, img, text):\n",
    "        view1_feature = self.img_net(img)    \n",
    "        view2_feature = self.text_net(text)  \n",
    "        view1_feature = self.linearLayer(view1_feature)\n",
    "        view2_feature = self.linearLayer1(view2_feature)\n",
    "\n",
    "        view1_predict = self.linearLayer2(view1_feature)      \n",
    "        view2_predict = self.linearLayer2(view2_feature)\n",
    "        return view1_feature, view2_feature, view1_predict, view2_predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataSet(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            images,\n",
    "            texts,\n",
    "            labels):\n",
    "        self.images = images\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.images[index]                                \n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "        return img, text, label\n",
    "\n",
    "    def __len__(self):\n",
    "        count = len(self.images)\n",
    "        assert len(                                        \n",
    "            self.images) == len(self.labels)\n",
    "        return count\n",
    "\n",
    "\n",
    "def ind2vec(ind, N=None):\n",
    "    ind = np.asarray(ind)                                 \n",
    "    if N is None:\n",
    "        N = ind.max() + 1\n",
    "    return np.arange(N) == np.repeat(ind, N, axis=1)\n",
    "\n",
    "def get_loader(path, batch_size):\n",
    "    img_train = loadmat(path+\"train_img.mat\")['train_img']\n",
    "    img_test = loadmat(path + \"test_img.mat\")['test_img']\n",
    "    text_train = loadmat(path+\"train_txt.mat\")['train_txt']\n",
    "    text_test = loadmat(path + \"test_txt.mat\")['test_txt']\n",
    "    label_train = loadmat(path+\"train_img_lab.mat\")['train_img_lab']\n",
    "    label_test = loadmat(path + \"test_img_lab.mat\")['test_img_lab']\n",
    "\n",
    "\n",
    "    label_train = ind2vec(label_train).astype(int)\n",
    "    label_test = ind2vec(label_test).astype(int)\n",
    "\n",
    "\n",
    "    imgs = {'train': img_train, 'test': img_test}\n",
    "    texts = {'train': text_train, 'test': text_test}\n",
    "    labels = {'train': label_train, 'test': label_test}\n",
    "    dataset = {x: CustomDataSet(images=imgs[x], texts=texts[x], labels=labels[x])\n",
    "               for x in ['train', 'test']}\n",
    "\n",
    "    shuffle = {'train': False, 'test': False}\n",
    "\n",
    "    dataloader = {x: DataLoader(dataset[x], batch_size=batch_size,\n",
    "                                shuffle=shuffle[x], num_workers=0) for x in ['train', 'test']}\n",
    "\n",
    "   \n",
    "    img_dim = img_train.shape[1]\n",
    "    text_dim = text_train.shape[1]\n",
    "    num_class = label_train.shape[1]\n",
    "\n",
    "\n",
    "    input_data_par = {}\n",
    "    input_data_par['img_test'] = img_test\n",
    "    input_data_par['text_test'] = text_test\n",
    "    input_data_par['label_test'] = label_test\n",
    "    input_data_par['img_train'] = img_train\n",
    "    input_data_par['text_train'] = text_train\n",
    "    input_data_par['label_train'] = label_train\n",
    "    input_data_par['img_dim'] = img_dim\n",
    "    input_data_par['text_dim'] = text_dim\n",
    "    input_data_par['num_class'] = num_class\n",
    "\n",
    "    return dataloader, input_data_par"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fx_calc_map_label(image, text, label, k=0, dist_method='COS'):\n",
    "    if dist_method == 'L2':\n",
    "        dist = scipy.spatial.distance.cdist(image, text, 'euclidean')\n",
    "    elif dist_method == 'COS':\n",
    "        dist = scipy.spatial.distance.cdist(image, text, 'cosine')\n",
    "    ord = dist.argsort()\n",
    "    numcases = dist.shape[0]\n",
    "    if k == 0:\n",
    "        k = numcases\n",
    "    res = []\n",
    "    for i in range(numcases):\n",
    "        order = ord[i]\n",
    "        p = 0.0\n",
    "        r = 0.0\n",
    "        for j in range(k):\n",
    "            if label[i] == label[order[j]]:\n",
    "                r += 1\n",
    "                p += (r / (j + 1))\n",
    "        if r > 0:\n",
    "            res += [p / r]\n",
    "        else:\n",
    "            res += [0]\n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 损失函数构建"
   ]
  },
  {
   "attachments": {
    "1658130327394.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建三元组损失\n",
    "![1658130327394.png](attachment:1658130327394.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#余弦距离\n",
    "def cos_distance(source, target):\n",
    "    cos_sim = F.cosine_similarity(source.unsqueeze(1), target, dim=-1)\n",
    "    distances = torch.clamp(1 - cos_sim, 0)\n",
    "    return distances\n",
    "\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, source, s_labels, target=None, t_labels=None, margin=0):\n",
    "        if target is None:\n",
    "            target = source\n",
    "        if t_labels is None:\n",
    "            t_labels = s_labels\n",
    "\n",
    "        pairwise_dist = cos_distance(source, target)\n",
    "#锚点与正样本的距离a\n",
    "        anchor_positive_dist = pairwise_dist.unsqueeze(2)\n",
    "#锚点与负样本的距离b\n",
    "        anchor_negative_dist = pairwise_dist.unsqueeze(1)\n",
    "#a-b+边距\n",
    "        triplet_loss = anchor_positive_dist - anchor_negative_dist + margin\n",
    "#将小于0的值修改为0\n",
    "        triplet_loss = triplet_loss.clamp(0)\n",
    "\n",
    "        valid_triplets = triplet_loss.gt(1e-16).float()\n",
    "        num_positive_triplets = valid_triplets.sum()\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            triplet_loss = triplet_loss.sum() / (num_positive_triplets + 1e-16)\n",
    "        elif self.reduction == 'sum':\n",
    "            triplet_loss = triplet_loss.sum()\n",
    "\n",
    "        return triplet_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(view1_feature, view2_feature, view1_predict, view2_predict, labels_1, labels_2, alpha, beta,gamma):\n",
    "\n",
    "    tri_loss = TripletLoss(reduction='mean')\n",
    "    tri_i2t = tri_loss(view1_feature, labels_1.float(), target=view2_feature, margin=0.1)\n",
    "    tri_t2i = tri_loss(view2_feature, labels_2.float(), target=view1_feature, margin=0.1)\n",
    "    cos_tri = tri_i2t + tri_t2i\n",
    " \n",
    "    floss = ((view1_feature - view2_feature)**2).sum(1).sqrt().mean()\n",
    "    lloss = ((view1_predict-labels_1.float())**2).sum(1).sqrt().mean() + ((view2_predict-labels_2.float())**2).sum(1).sqrt().mean()\n",
    "\n",
    "    im_loss = alpha * cos_tri + beta*floss+ gamma*lloss\n",
    "\n",
    "    return im_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, data_loaders, optimizer, alpha, beta,gamma, num_epochs):\n",
    "    since = time.time()\n",
    "    test_img_acc_history = []\n",
    "    test_txt_acc_history = []\n",
    "    epoch_loss_history =[]\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 20)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects_img = 0\n",
    "            running_corrects_txt = 0\n",
    "            for imgs, txts, labels in data_loaders[phase]:\n",
    "                if torch.sum(imgs != imgs)>1 or torch.sum(txts != txts)>1:\n",
    "                    print(\"Data contains Nan.\")\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                  \n",
    "                    if torch.cuda.is_available():\n",
    "                        imgs = imgs.cuda()\n",
    "                        txts = txts.cuda()\n",
    "                        labels = labels.cuda()\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    view1_feature, view2_feature, view1_predict, view2_predict = model(imgs, txts)\n",
    "\n",
    "                    loss = calc_loss(view1_feature, view2_feature, view1_predict,\n",
    "                                     view2_predict, labels, labels, alpha, beta,gamma)\n",
    "\n",
    "                    img_preds = view1_predict\n",
    "                    txt_preds = view2_predict\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                running_corrects_img += torch.sum(torch.argmax(img_preds, dim=1) == torch.argmax(labels, dim=1))\n",
    "                running_corrects_txt += torch.sum(torch.argmax(txt_preds, dim=1) == torch.argmax(labels, dim=1))\n",
    "\n",
    "            epoch_loss = running_loss / len(data_loaders[phase].dataset)\n",
    "            t_imgs, t_txts, t_labels = [], [], []\n",
    "            with torch.no_grad():\n",
    "                for imgs, txts, labels in data_loaders['test']:\n",
    "                    if torch.cuda.is_available():\n",
    "                            imgs = imgs.cuda()\n",
    "                            txts = txts.cuda()\n",
    "                            labels = labels.cuda()\n",
    "                    t_view1_feature, t_view2_feature, _, _ = model(imgs, txts)\n",
    "                    t_imgs.append(t_view1_feature.cpu().numpy())\n",
    "                    t_txts.append(t_view2_feature.cpu().numpy())\n",
    "                    t_labels.append(labels.cpu().numpy())\n",
    "            t_imgs = np.concatenate(t_imgs)\n",
    "            t_txts = np.concatenate(t_txts)\n",
    "            t_labels = np.concatenate(t_labels).argmax(1)\n",
    "            img2text = fx_calc_map_label(t_imgs, t_txts, t_labels)\n",
    "            txt2img = fx_calc_map_label(t_txts, t_imgs, t_labels)\n",
    "\n",
    "            print('{} Loss: {:.4f} Img2Txt: {:.4f}  Txt2Img: {:.4f}'.format(phase, epoch_loss, img2text, txt2img))\n",
    "\n",
    "            if phase == 'test' and (img2text + txt2img) / 2. > best_acc:\n",
    "                best_acc = (img2text + txt2img) / 2.\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            if phase == 'test':\n",
    "                test_img_acc_history.append(img2text)\n",
    "                test_txt_acc_history.append(txt2img)\n",
    "                epoch_loss_history.append(epoch_loss)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best average ACC: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, test_img_acc_history, test_txt_acc_history, epoch_loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主函数+参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载数据\n",
      "开始训练\n",
      "Epoch 1/130\n",
      "--------------------\n",
      "train Loss: 0.2704 Img2Txt: 0.2171  Txt2Img: 0.2132\n",
      "test Loss: 0.2217 Img2Txt: 0.2171  Txt2Img: 0.2132\n",
      "Epoch 2/130\n",
      "--------------------\n",
      "train Loss: 0.2229 Img2Txt: 0.4099  Txt2Img: 0.4798\n",
      "test Loss: 0.1951 Img2Txt: 0.4099  Txt2Img: 0.4798\n",
      "Epoch 3/130\n",
      "--------------------\n",
      "train Loss: 0.1990 Img2Txt: 0.5426  Txt2Img: 0.5804\n",
      "test Loss: 0.1780 Img2Txt: 0.5426  Txt2Img: 0.5804\n",
      "Epoch 4/130\n",
      "--------------------\n",
      "train Loss: 0.1784 Img2Txt: 0.5932  Txt2Img: 0.6240\n",
      "test Loss: 0.1654 Img2Txt: 0.5932  Txt2Img: 0.6240\n",
      "Epoch 5/130\n",
      "--------------------\n",
      "train Loss: 0.1610 Img2Txt: 0.6113  Txt2Img: 0.6585\n",
      "test Loss: 0.1577 Img2Txt: 0.6113  Txt2Img: 0.6585\n",
      "Epoch 6/130\n",
      "--------------------\n",
      "train Loss: 0.1489 Img2Txt: 0.6362  Txt2Img: 0.6808\n",
      "test Loss: 0.1550 Img2Txt: 0.6362  Txt2Img: 0.6808\n",
      "Epoch 7/130\n",
      "--------------------\n",
      "train Loss: 0.1426 Img2Txt: 0.6357  Txt2Img: 0.6748\n",
      "test Loss: 0.1537 Img2Txt: 0.6357  Txt2Img: 0.6748\n",
      "Epoch 8/130\n",
      "--------------------\n",
      "train Loss: 0.1369 Img2Txt: 0.6615  Txt2Img: 0.7022\n",
      "test Loss: 0.1532 Img2Txt: 0.6615  Txt2Img: 0.7022\n",
      "Epoch 9/130\n",
      "--------------------\n",
      "train Loss: 0.1342 Img2Txt: 0.6626  Txt2Img: 0.7007\n",
      "test Loss: 0.1536 Img2Txt: 0.6626  Txt2Img: 0.7007\n",
      "Epoch 10/130\n",
      "--------------------\n",
      "train Loss: 0.1314 Img2Txt: 0.6698  Txt2Img: 0.6956\n",
      "test Loss: 0.1516 Img2Txt: 0.6698  Txt2Img: 0.6956\n",
      "Epoch 11/130\n",
      "--------------------\n",
      "train Loss: 0.1272 Img2Txt: 0.6803  Txt2Img: 0.7025\n",
      "test Loss: 0.1508 Img2Txt: 0.6803  Txt2Img: 0.7025\n",
      "Epoch 12/130\n",
      "--------------------\n",
      "train Loss: 0.1222 Img2Txt: 0.6670  Txt2Img: 0.7078\n",
      "test Loss: 0.1518 Img2Txt: 0.6670  Txt2Img: 0.7078\n",
      "Epoch 13/130\n",
      "--------------------\n",
      "train Loss: 0.1232 Img2Txt: 0.6635  Txt2Img: 0.7079\n",
      "test Loss: 0.1471 Img2Txt: 0.6635  Txt2Img: 0.7079\n",
      "Epoch 14/130\n",
      "--------------------\n",
      "train Loss: 0.1175 Img2Txt: 0.6911  Txt2Img: 0.7148\n",
      "test Loss: 0.1468 Img2Txt: 0.6911  Txt2Img: 0.7148\n",
      "Epoch 15/130\n",
      "--------------------\n",
      "train Loss: 0.1161 Img2Txt: 0.6827  Txt2Img: 0.7136\n",
      "test Loss: 0.1455 Img2Txt: 0.6827  Txt2Img: 0.7136\n",
      "Epoch 16/130\n",
      "--------------------\n",
      "train Loss: 0.1121 Img2Txt: 0.6751  Txt2Img: 0.7103\n",
      "test Loss: 0.1453 Img2Txt: 0.6751  Txt2Img: 0.7103\n",
      "Epoch 17/130\n",
      "--------------------\n",
      "train Loss: 0.1105 Img2Txt: 0.6730  Txt2Img: 0.7107\n",
      "test Loss: 0.1453 Img2Txt: 0.6730  Txt2Img: 0.7107\n",
      "Epoch 18/130\n",
      "--------------------\n",
      "train Loss: 0.1068 Img2Txt: 0.6731  Txt2Img: 0.7128\n",
      "test Loss: 0.1438 Img2Txt: 0.6731  Txt2Img: 0.7128\n",
      "Epoch 19/130\n",
      "--------------------\n",
      "train Loss: 0.1055 Img2Txt: 0.6833  Txt2Img: 0.7123\n",
      "test Loss: 0.1439 Img2Txt: 0.6833  Txt2Img: 0.7123\n",
      "Epoch 20/130\n",
      "--------------------\n",
      "train Loss: 0.1029 Img2Txt: 0.6763  Txt2Img: 0.7115\n",
      "test Loss: 0.1392 Img2Txt: 0.6763  Txt2Img: 0.7115\n",
      "Epoch 21/130\n",
      "--------------------\n",
      "train Loss: 0.1009 Img2Txt: 0.6772  Txt2Img: 0.7088\n",
      "test Loss: 0.1385 Img2Txt: 0.6772  Txt2Img: 0.7088\n",
      "Epoch 22/130\n",
      "--------------------\n",
      "train Loss: 0.0966 Img2Txt: 0.6924  Txt2Img: 0.7144\n",
      "test Loss: 0.1390 Img2Txt: 0.6924  Txt2Img: 0.7144\n",
      "Epoch 23/130\n",
      "--------------------\n",
      "train Loss: 0.0924 Img2Txt: 0.6866  Txt2Img: 0.7211\n",
      "test Loss: 0.1392 Img2Txt: 0.6866  Txt2Img: 0.7211\n",
      "Epoch 24/130\n",
      "--------------------\n",
      "train Loss: 0.0943 Img2Txt: 0.6948  Txt2Img: 0.7126\n",
      "test Loss: 0.1385 Img2Txt: 0.6948  Txt2Img: 0.7126\n",
      "Epoch 25/130\n",
      "--------------------\n",
      "train Loss: 0.0958 Img2Txt: 0.6799  Txt2Img: 0.7134\n",
      "test Loss: 0.1379 Img2Txt: 0.6799  Txt2Img: 0.7134\n",
      "Epoch 26/130\n",
      "--------------------\n",
      "train Loss: 0.0913 Img2Txt: 0.6735  Txt2Img: 0.7043\n",
      "test Loss: 0.1384 Img2Txt: 0.6735  Txt2Img: 0.7043\n",
      "Epoch 27/130\n",
      "--------------------\n",
      "train Loss: 0.0934 Img2Txt: 0.6719  Txt2Img: 0.7004\n",
      "test Loss: 0.1376 Img2Txt: 0.6719  Txt2Img: 0.7004\n",
      "Epoch 28/130\n",
      "--------------------\n",
      "train Loss: 0.0906 Img2Txt: 0.6904  Txt2Img: 0.7322\n",
      "test Loss: 0.1375 Img2Txt: 0.6904  Txt2Img: 0.7322\n",
      "Epoch 29/130\n",
      "--------------------\n",
      "train Loss: 0.0921 Img2Txt: 0.6555  Txt2Img: 0.7044\n",
      "test Loss: 0.1374 Img2Txt: 0.6555  Txt2Img: 0.7044\n",
      "Epoch 30/130\n",
      "--------------------\n",
      "train Loss: 0.0915 Img2Txt: 0.6634  Txt2Img: 0.6968\n",
      "test Loss: 0.1402 Img2Txt: 0.6634  Txt2Img: 0.6968\n",
      "Epoch 31/130\n",
      "--------------------\n",
      "train Loss: 0.0921 Img2Txt: 0.6748  Txt2Img: 0.7085\n",
      "test Loss: 0.1360 Img2Txt: 0.6748  Txt2Img: 0.7085\n",
      "Epoch 32/130\n",
      "--------------------\n",
      "train Loss: 0.0833 Img2Txt: 0.6526  Txt2Img: 0.7046\n",
      "test Loss: 0.1345 Img2Txt: 0.6526  Txt2Img: 0.7046\n",
      "Epoch 33/130\n",
      "--------------------\n",
      "train Loss: 0.0856 Img2Txt: 0.6964  Txt2Img: 0.7124\n",
      "test Loss: 0.1340 Img2Txt: 0.6964  Txt2Img: 0.7124\n",
      "Epoch 34/130\n",
      "--------------------\n",
      "train Loss: 0.0845 Img2Txt: 0.6671  Txt2Img: 0.6992\n",
      "test Loss: 0.1357 Img2Txt: 0.6671  Txt2Img: 0.6992\n",
      "Epoch 35/130\n",
      "--------------------\n",
      "train Loss: 0.0856 Img2Txt: 0.6800  Txt2Img: 0.7011\n",
      "test Loss: 0.1361 Img2Txt: 0.6800  Txt2Img: 0.7011\n",
      "Epoch 36/130\n",
      "--------------------\n",
      "train Loss: 0.0826 Img2Txt: 0.6847  Txt2Img: 0.7059\n",
      "test Loss: 0.1361 Img2Txt: 0.6847  Txt2Img: 0.7059\n",
      "Epoch 37/130\n",
      "--------------------\n",
      "train Loss: 0.0824 Img2Txt: 0.6720  Txt2Img: 0.6995\n",
      "test Loss: 0.1320 Img2Txt: 0.6720  Txt2Img: 0.6995\n",
      "Epoch 38/130\n",
      "--------------------\n",
      "train Loss: 0.0786 Img2Txt: 0.6585  Txt2Img: 0.6978\n",
      "test Loss: 0.1357 Img2Txt: 0.6585  Txt2Img: 0.6978\n",
      "Epoch 39/130\n",
      "--------------------\n",
      "train Loss: 0.0800 Img2Txt: 0.6898  Txt2Img: 0.7037\n",
      "test Loss: 0.1340 Img2Txt: 0.6898  Txt2Img: 0.7037\n",
      "Epoch 40/130\n",
      "--------------------\n",
      "train Loss: 0.0797 Img2Txt: 0.6509  Txt2Img: 0.6921\n",
      "test Loss: 0.1345 Img2Txt: 0.6509  Txt2Img: 0.6921\n",
      "Epoch 41/130\n",
      "--------------------\n",
      "train Loss: 0.0796 Img2Txt: 0.6810  Txt2Img: 0.7028\n",
      "test Loss: 0.1323 Img2Txt: 0.6810  Txt2Img: 0.7028\n",
      "Epoch 42/130\n",
      "--------------------\n",
      "train Loss: 0.0774 Img2Txt: 0.6405  Txt2Img: 0.6941\n",
      "test Loss: 0.1338 Img2Txt: 0.6405  Txt2Img: 0.6941\n",
      "Epoch 43/130\n",
      "--------------------\n",
      "train Loss: 0.0778 Img2Txt: 0.7031  Txt2Img: 0.7057\n",
      "test Loss: 0.1349 Img2Txt: 0.7031  Txt2Img: 0.7057\n",
      "Epoch 44/130\n",
      "--------------------\n",
      "train Loss: 0.0788 Img2Txt: 0.6478  Txt2Img: 0.7005\n",
      "test Loss: 0.1323 Img2Txt: 0.6478  Txt2Img: 0.7005\n",
      "Epoch 45/130\n",
      "--------------------\n",
      "train Loss: 0.0793 Img2Txt: 0.6923  Txt2Img: 0.7136\n",
      "test Loss: 0.1335 Img2Txt: 0.6923  Txt2Img: 0.7136\n",
      "Epoch 46/130\n",
      "--------------------\n",
      "train Loss: 0.0770 Img2Txt: 0.6490  Txt2Img: 0.6857\n",
      "test Loss: 0.1322 Img2Txt: 0.6490  Txt2Img: 0.6857\n",
      "Epoch 47/130\n",
      "--------------------\n",
      "train Loss: 0.0791 Img2Txt: 0.6947  Txt2Img: 0.7051\n",
      "test Loss: 0.1353 Img2Txt: 0.6947  Txt2Img: 0.7051\n",
      "Epoch 48/130\n",
      "--------------------\n",
      "train Loss: 0.0770 Img2Txt: 0.6572  Txt2Img: 0.6989\n",
      "test Loss: 0.1311 Img2Txt: 0.6572  Txt2Img: 0.6989\n",
      "Epoch 49/130\n",
      "--------------------\n",
      "train Loss: 0.0775 Img2Txt: 0.6824  Txt2Img: 0.6963\n",
      "test Loss: 0.1333 Img2Txt: 0.6824  Txt2Img: 0.6963\n",
      "Epoch 50/130\n",
      "--------------------\n",
      "train Loss: 0.0765 Img2Txt: 0.6629  Txt2Img: 0.6901\n",
      "test Loss: 0.1324 Img2Txt: 0.6629  Txt2Img: 0.6901\n",
      "Epoch 51/130\n",
      "--------------------\n",
      "train Loss: 0.0766 Img2Txt: 0.6483  Txt2Img: 0.6918\n",
      "test Loss: 0.1322 Img2Txt: 0.6483  Txt2Img: 0.6918\n",
      "Epoch 52/130\n",
      "--------------------\n",
      "train Loss: 0.0742 Img2Txt: 0.6895  Txt2Img: 0.7031\n",
      "test Loss: 0.1323 Img2Txt: 0.6895  Txt2Img: 0.7031\n",
      "Epoch 53/130\n",
      "--------------------\n",
      "train Loss: 0.0741 Img2Txt: 0.6437  Txt2Img: 0.6953\n",
      "test Loss: 0.1322 Img2Txt: 0.6437  Txt2Img: 0.6953\n",
      "Epoch 54/130\n",
      "--------------------\n",
      "train Loss: 0.0708 Img2Txt: 0.6568  Txt2Img: 0.6947\n",
      "test Loss: 0.1314 Img2Txt: 0.6568  Txt2Img: 0.6947\n",
      "Epoch 55/130\n",
      "--------------------\n",
      "train Loss: 0.0742 Img2Txt: 0.6682  Txt2Img: 0.6864\n",
      "test Loss: 0.1318 Img2Txt: 0.6682  Txt2Img: 0.6864\n",
      "Epoch 56/130\n",
      "--------------------\n",
      "train Loss: 0.0755 Img2Txt: 0.6629  Txt2Img: 0.6985\n",
      "test Loss: 0.1363 Img2Txt: 0.6629  Txt2Img: 0.6985\n",
      "Epoch 57/130\n",
      "--------------------\n",
      "train Loss: 0.0766 Img2Txt: 0.6667  Txt2Img: 0.7022\n",
      "test Loss: 0.1296 Img2Txt: 0.6667  Txt2Img: 0.7022\n",
      "Epoch 58/130\n",
      "--------------------\n",
      "train Loss: 0.0696 Img2Txt: 0.6502  Txt2Img: 0.6824\n",
      "test Loss: 0.1304 Img2Txt: 0.6502  Txt2Img: 0.6824\n",
      "Epoch 59/130\n",
      "--------------------\n",
      "train Loss: 0.0713 Img2Txt: 0.6550  Txt2Img: 0.6906\n",
      "test Loss: 0.1311 Img2Txt: 0.6550  Txt2Img: 0.6906\n",
      "Epoch 60/130\n",
      "--------------------\n",
      "train Loss: 0.0704 Img2Txt: 0.6524  Txt2Img: 0.6998\n",
      "test Loss: 0.1305 Img2Txt: 0.6524  Txt2Img: 0.6998\n",
      "Epoch 61/130\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0745 Img2Txt: 0.6591  Txt2Img: 0.6992\n",
      "test Loss: 0.1332 Img2Txt: 0.6591  Txt2Img: 0.6992\n",
      "Epoch 62/130\n",
      "--------------------\n",
      "train Loss: 0.0698 Img2Txt: 0.6371  Txt2Img: 0.6823\n",
      "test Loss: 0.1281 Img2Txt: 0.6371  Txt2Img: 0.6823\n",
      "Epoch 63/130\n",
      "--------------------\n",
      "train Loss: 0.0705 Img2Txt: 0.6439  Txt2Img: 0.6847\n",
      "test Loss: 0.1325 Img2Txt: 0.6439  Txt2Img: 0.6847\n",
      "Epoch 64/130\n",
      "--------------------\n",
      "train Loss: 0.0712 Img2Txt: 0.6630  Txt2Img: 0.7018\n",
      "test Loss: 0.1296 Img2Txt: 0.6630  Txt2Img: 0.7018\n",
      "Epoch 65/130\n",
      "--------------------\n",
      "train Loss: 0.0724 Img2Txt: 0.6563  Txt2Img: 0.6909\n",
      "test Loss: 0.1301 Img2Txt: 0.6563  Txt2Img: 0.6909\n",
      "Epoch 66/130\n",
      "--------------------\n",
      "train Loss: 0.0666 Img2Txt: 0.6883  Txt2Img: 0.6933\n",
      "test Loss: 0.1265 Img2Txt: 0.6883  Txt2Img: 0.6933\n",
      "Epoch 67/130\n",
      "--------------------\n",
      "train Loss: 0.0644 Img2Txt: 0.6575  Txt2Img: 0.6991\n",
      "test Loss: 0.1313 Img2Txt: 0.6575  Txt2Img: 0.6991\n",
      "Epoch 68/130\n",
      "--------------------\n",
      "train Loss: 0.0697 Img2Txt: 0.6676  Txt2Img: 0.6881\n",
      "test Loss: 0.1305 Img2Txt: 0.6676  Txt2Img: 0.6881\n",
      "Epoch 69/130\n",
      "--------------------\n",
      "train Loss: 0.0700 Img2Txt: 0.6847  Txt2Img: 0.6950\n",
      "test Loss: 0.1284 Img2Txt: 0.6847  Txt2Img: 0.6950\n",
      "Epoch 70/130\n",
      "--------------------\n",
      "train Loss: 0.0645 Img2Txt: 0.6515  Txt2Img: 0.6744\n",
      "test Loss: 0.1294 Img2Txt: 0.6515  Txt2Img: 0.6744\n",
      "Epoch 71/130\n",
      "--------------------\n",
      "train Loss: 0.0715 Img2Txt: 0.6461  Txt2Img: 0.6864\n",
      "test Loss: 0.1316 Img2Txt: 0.6461  Txt2Img: 0.6864\n",
      "Epoch 72/130\n",
      "--------------------\n",
      "train Loss: 0.0667 Img2Txt: 0.6801  Txt2Img: 0.6970\n",
      "test Loss: 0.1285 Img2Txt: 0.6801  Txt2Img: 0.6970\n",
      "Epoch 73/130\n",
      "--------------------\n",
      "train Loss: 0.0679 Img2Txt: 0.6547  Txt2Img: 0.6845\n",
      "test Loss: 0.1298 Img2Txt: 0.6547  Txt2Img: 0.6845\n",
      "Epoch 74/130\n",
      "--------------------\n",
      "train Loss: 0.0658 Img2Txt: 0.6589  Txt2Img: 0.6848\n",
      "test Loss: 0.1293 Img2Txt: 0.6589  Txt2Img: 0.6848\n",
      "Epoch 75/130\n",
      "--------------------\n",
      "train Loss: 0.0670 Img2Txt: 0.6684  Txt2Img: 0.7003\n",
      "test Loss: 0.1299 Img2Txt: 0.6684  Txt2Img: 0.7003\n",
      "Epoch 76/130\n",
      "--------------------\n",
      "train Loss: 0.0671 Img2Txt: 0.6701  Txt2Img: 0.6936\n",
      "test Loss: 0.1274 Img2Txt: 0.6701  Txt2Img: 0.6936\n",
      "Epoch 77/130\n",
      "--------------------\n",
      "train Loss: 0.0645 Img2Txt: 0.6640  Txt2Img: 0.6850\n",
      "test Loss: 0.1317 Img2Txt: 0.6640  Txt2Img: 0.6850\n",
      "Epoch 78/130\n",
      "--------------------\n",
      "train Loss: 0.0675 Img2Txt: 0.6495  Txt2Img: 0.6858\n",
      "test Loss: 0.1257 Img2Txt: 0.6495  Txt2Img: 0.6858\n",
      "Epoch 79/130\n",
      "--------------------\n",
      "train Loss: 0.0634 Img2Txt: 0.6355  Txt2Img: 0.6795\n",
      "test Loss: 0.1323 Img2Txt: 0.6355  Txt2Img: 0.6795\n",
      "Epoch 80/130\n",
      "--------------------\n",
      "train Loss: 0.0712 Img2Txt: 0.6779  Txt2Img: 0.6882\n",
      "test Loss: 0.1273 Img2Txt: 0.6779  Txt2Img: 0.6882\n",
      "Epoch 81/130\n",
      "--------------------\n",
      "train Loss: 0.0601 Img2Txt: 0.6631  Txt2Img: 0.6934\n",
      "test Loss: 0.1293 Img2Txt: 0.6631  Txt2Img: 0.6934\n",
      "Epoch 82/130\n",
      "--------------------\n",
      "train Loss: 0.0655 Img2Txt: 0.6565  Txt2Img: 0.6840\n",
      "test Loss: 0.1265 Img2Txt: 0.6565  Txt2Img: 0.6840\n",
      "Epoch 83/130\n",
      "--------------------\n",
      "train Loss: 0.0643 Img2Txt: 0.6477  Txt2Img: 0.6930\n",
      "test Loss: 0.1272 Img2Txt: 0.6477  Txt2Img: 0.6930\n",
      "Epoch 84/130\n",
      "--------------------\n",
      "train Loss: 0.0600 Img2Txt: 0.6681  Txt2Img: 0.7010\n",
      "test Loss: 0.1273 Img2Txt: 0.6681  Txt2Img: 0.7010\n",
      "Epoch 85/130\n",
      "--------------------\n",
      "train Loss: 0.0622 Img2Txt: 0.6748  Txt2Img: 0.6768\n",
      "test Loss: 0.1278 Img2Txt: 0.6748  Txt2Img: 0.6768\n",
      "Epoch 86/130\n",
      "--------------------\n",
      "train Loss: 0.0618 Img2Txt: 0.6445  Txt2Img: 0.6898\n",
      "test Loss: 0.1262 Img2Txt: 0.6445  Txt2Img: 0.6898\n",
      "Epoch 87/130\n",
      "--------------------\n",
      "train Loss: 0.0622 Img2Txt: 0.6722  Txt2Img: 0.6808\n",
      "test Loss: 0.1263 Img2Txt: 0.6722  Txt2Img: 0.6808\n",
      "Epoch 88/130\n",
      "--------------------\n",
      "train Loss: 0.0621 Img2Txt: 0.6529  Txt2Img: 0.6871\n",
      "test Loss: 0.1302 Img2Txt: 0.6529  Txt2Img: 0.6871\n",
      "Epoch 89/130\n",
      "--------------------\n",
      "train Loss: 0.0627 Img2Txt: 0.6573  Txt2Img: 0.6873\n",
      "test Loss: 0.1274 Img2Txt: 0.6573  Txt2Img: 0.6873\n",
      "Epoch 90/130\n",
      "--------------------\n",
      "train Loss: 0.0646 Img2Txt: 0.6591  Txt2Img: 0.6813\n",
      "test Loss: 0.1273 Img2Txt: 0.6591  Txt2Img: 0.6813\n",
      "Epoch 91/130\n",
      "--------------------\n",
      "train Loss: 0.0617 Img2Txt: 0.6378  Txt2Img: 0.6817\n",
      "test Loss: 0.1269 Img2Txt: 0.6378  Txt2Img: 0.6817\n",
      "Epoch 92/130\n",
      "--------------------\n",
      "train Loss: 0.0611 Img2Txt: 0.6728  Txt2Img: 0.6874\n",
      "test Loss: 0.1290 Img2Txt: 0.6728  Txt2Img: 0.6874\n",
      "Epoch 93/130\n",
      "--------------------\n",
      "train Loss: 0.0615 Img2Txt: 0.6502  Txt2Img: 0.6944\n",
      "test Loss: 0.1275 Img2Txt: 0.6502  Txt2Img: 0.6944\n",
      "Epoch 94/130\n",
      "--------------------\n",
      "train Loss: 0.0626 Img2Txt: 0.6610  Txt2Img: 0.6856\n",
      "test Loss: 0.1259 Img2Txt: 0.6610  Txt2Img: 0.6856\n",
      "Epoch 95/130\n",
      "--------------------\n",
      "train Loss: 0.0617 Img2Txt: 0.6386  Txt2Img: 0.6820\n",
      "test Loss: 0.1303 Img2Txt: 0.6386  Txt2Img: 0.6820\n",
      "Epoch 96/130\n",
      "--------------------\n",
      "train Loss: 0.0632 Img2Txt: 0.6697  Txt2Img: 0.6845\n",
      "test Loss: 0.1262 Img2Txt: 0.6697  Txt2Img: 0.6845\n",
      "Epoch 97/130\n",
      "--------------------\n",
      "train Loss: 0.0582 Img2Txt: 0.6530  Txt2Img: 0.6952\n",
      "test Loss: 0.1285 Img2Txt: 0.6530  Txt2Img: 0.6952\n",
      "Epoch 98/130\n",
      "--------------------\n",
      "train Loss: 0.0651 Img2Txt: 0.6462  Txt2Img: 0.6823\n",
      "test Loss: 0.1264 Img2Txt: 0.6462  Txt2Img: 0.6823\n",
      "Epoch 99/130\n",
      "--------------------\n",
      "train Loss: 0.0584 Img2Txt: 0.6475  Txt2Img: 0.6799\n",
      "test Loss: 0.1291 Img2Txt: 0.6475  Txt2Img: 0.6799\n",
      "Epoch 100/130\n",
      "--------------------\n",
      "train Loss: 0.0602 Img2Txt: 0.6473  Txt2Img: 0.6831\n",
      "test Loss: 0.1252 Img2Txt: 0.6473  Txt2Img: 0.6831\n",
      "Epoch 101/130\n",
      "--------------------\n",
      "train Loss: 0.0585 Img2Txt: 0.6574  Txt2Img: 0.6885\n",
      "test Loss: 0.1286 Img2Txt: 0.6574  Txt2Img: 0.6885\n",
      "Epoch 102/130\n",
      "--------------------\n",
      "train Loss: 0.0614 Img2Txt: 0.6539  Txt2Img: 0.6795\n",
      "test Loss: 0.1266 Img2Txt: 0.6539  Txt2Img: 0.6795\n",
      "Epoch 103/130\n",
      "--------------------\n",
      "train Loss: 0.0604 Img2Txt: 0.6373  Txt2Img: 0.6751\n",
      "test Loss: 0.1292 Img2Txt: 0.6373  Txt2Img: 0.6751\n",
      "Epoch 104/130\n",
      "--------------------\n",
      "train Loss: 0.0611 Img2Txt: 0.6522  Txt2Img: 0.6838\n",
      "test Loss: 0.1261 Img2Txt: 0.6522  Txt2Img: 0.6838\n",
      "Epoch 105/130\n",
      "--------------------\n",
      "train Loss: 0.0598 Img2Txt: 0.6419  Txt2Img: 0.6889\n",
      "test Loss: 0.1284 Img2Txt: 0.6419  Txt2Img: 0.6889\n",
      "Epoch 106/130\n",
      "--------------------\n",
      "train Loss: 0.0608 Img2Txt: 0.6540  Txt2Img: 0.6822\n",
      "test Loss: 0.1251 Img2Txt: 0.6540  Txt2Img: 0.6822\n",
      "Epoch 107/130\n",
      "--------------------\n",
      "train Loss: 0.0588 Img2Txt: 0.6500  Txt2Img: 0.6909\n",
      "test Loss: 0.1277 Img2Txt: 0.6500  Txt2Img: 0.6909\n",
      "Epoch 108/130\n",
      "--------------------\n",
      "train Loss: 0.0601 Img2Txt: 0.6471  Txt2Img: 0.6782\n",
      "test Loss: 0.1272 Img2Txt: 0.6471  Txt2Img: 0.6782\n",
      "Epoch 109/130\n",
      "--------------------\n",
      "train Loss: 0.0585 Img2Txt: 0.6478  Txt2Img: 0.6878\n",
      "test Loss: 0.1261 Img2Txt: 0.6478  Txt2Img: 0.6878\n",
      "Epoch 110/130\n",
      "--------------------\n",
      "train Loss: 0.0561 Img2Txt: 0.6454  Txt2Img: 0.6796\n",
      "test Loss: 0.1261 Img2Txt: 0.6454  Txt2Img: 0.6796\n",
      "Epoch 111/130\n",
      "--------------------\n",
      "train Loss: 0.0606 Img2Txt: 0.6570  Txt2Img: 0.6899\n",
      "test Loss: 0.1268 Img2Txt: 0.6570  Txt2Img: 0.6899\n",
      "Epoch 112/130\n",
      "--------------------\n",
      "train Loss: 0.0576 Img2Txt: 0.6347  Txt2Img: 0.6789\n",
      "test Loss: 0.1283 Img2Txt: 0.6347  Txt2Img: 0.6789\n",
      "Epoch 113/130\n",
      "--------------------\n",
      "train Loss: 0.0588 Img2Txt: 0.6501  Txt2Img: 0.6889\n",
      "test Loss: 0.1255 Img2Txt: 0.6501  Txt2Img: 0.6889\n",
      "Epoch 114/130\n",
      "--------------------\n",
      "train Loss: 0.0550 Img2Txt: 0.6359  Txt2Img: 0.6784\n",
      "test Loss: 0.1270 Img2Txt: 0.6359  Txt2Img: 0.6784\n",
      "Epoch 115/130\n",
      "--------------------\n",
      "train Loss: 0.0614 Img2Txt: 0.6617  Txt2Img: 0.6888\n",
      "test Loss: 0.1254 Img2Txt: 0.6617  Txt2Img: 0.6888\n",
      "Epoch 116/130\n",
      "--------------------\n",
      "train Loss: 0.0550 Img2Txt: 0.6391  Txt2Img: 0.6845\n",
      "test Loss: 0.1270 Img2Txt: 0.6391  Txt2Img: 0.6845\n",
      "Epoch 117/130\n",
      "--------------------\n",
      "train Loss: 0.0570 Img2Txt: 0.6617  Txt2Img: 0.6895\n",
      "test Loss: 0.1248 Img2Txt: 0.6617  Txt2Img: 0.6895\n",
      "Epoch 118/130\n",
      "--------------------\n",
      "train Loss: 0.0568 Img2Txt: 0.6368  Txt2Img: 0.6853\n",
      "test Loss: 0.1278 Img2Txt: 0.6368  Txt2Img: 0.6853\n",
      "Epoch 119/130\n",
      "--------------------\n",
      "train Loss: 0.0571 Img2Txt: 0.6508  Txt2Img: 0.6890\n",
      "test Loss: 0.1249 Img2Txt: 0.6508  Txt2Img: 0.6890\n",
      "Epoch 120/130\n",
      "--------------------\n",
      "train Loss: 0.0548 Img2Txt: 0.6369  Txt2Img: 0.6920\n",
      "test Loss: 0.1264 Img2Txt: 0.6369  Txt2Img: 0.6920\n",
      "Epoch 121/130\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0567 Img2Txt: 0.6550  Txt2Img: 0.6865\n",
      "test Loss: 0.1265 Img2Txt: 0.6550  Txt2Img: 0.6865\n",
      "Epoch 122/130\n",
      "--------------------\n",
      "train Loss: 0.0567 Img2Txt: 0.6364  Txt2Img: 0.6852\n",
      "test Loss: 0.1264 Img2Txt: 0.6364  Txt2Img: 0.6852\n",
      "Epoch 123/130\n",
      "--------------------\n",
      "train Loss: 0.0555 Img2Txt: 0.6535  Txt2Img: 0.6888\n",
      "test Loss: 0.1254 Img2Txt: 0.6535  Txt2Img: 0.6888\n",
      "Epoch 124/130\n",
      "--------------------\n",
      "train Loss: 0.0548 Img2Txt: 0.6535  Txt2Img: 0.6922\n",
      "test Loss: 0.1257 Img2Txt: 0.6535  Txt2Img: 0.6922\n",
      "Epoch 125/130\n",
      "--------------------\n",
      "train Loss: 0.0554 Img2Txt: 0.6636  Txt2Img: 0.6888\n",
      "test Loss: 0.1250 Img2Txt: 0.6636  Txt2Img: 0.6888\n",
      "Epoch 126/130\n",
      "--------------------\n",
      "train Loss: 0.0531 Img2Txt: 0.6429  Txt2Img: 0.6794\n",
      "test Loss: 0.1263 Img2Txt: 0.6429  Txt2Img: 0.6794\n",
      "Epoch 127/130\n",
      "--------------------\n",
      "train Loss: 0.0565 Img2Txt: 0.6624  Txt2Img: 0.6901\n",
      "test Loss: 0.1250 Img2Txt: 0.6624  Txt2Img: 0.6901\n",
      "Epoch 128/130\n",
      "--------------------\n",
      "train Loss: 0.0502 Img2Txt: 0.6387  Txt2Img: 0.6858\n",
      "test Loss: 0.1259 Img2Txt: 0.6387  Txt2Img: 0.6858\n",
      "Epoch 129/130\n",
      "--------------------\n",
      "train Loss: 0.0574 Img2Txt: 0.6618  Txt2Img: 0.6885\n",
      "test Loss: 0.1253 Img2Txt: 0.6618  Txt2Img: 0.6885\n",
      "Epoch 130/130\n",
      "--------------------\n",
      "train Loss: 0.0500 Img2Txt: 0.6357  Txt2Img: 0.6810\n",
      "test Loss: 0.1261 Img2Txt: 0.6357  Txt2Img: 0.6810\n",
      "Training complete in 0m 53s\n",
      "Best average ACC: 0.711302\n",
      "训练完成\n",
      "在测试集评估\n",
      "...Image to Text MAP = 0.690430024096876\n",
      "...Text to Image MAP = 0.7321743013743085\n",
      "...Average MAP = 0.7113021627355922\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataset = 'pascal'\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    DATA_DIR = 'data/' + dataset + '/'\n",
    "    MAX_EPOCH = 130\n",
    "    alpha = 1e-3\n",
    "    beta = 1\n",
    "    gamma=10\n",
    "    weight_decay = 0\n",
    "    batch_size = 100\n",
    "    lr = 1e-4\n",
    "    betas = (0.5, 0.999)\n",
    "    print('加载数据')\n",
    "\n",
    "    data_loader, input_data_par = get_loader(DATA_DIR, batch_size)\n",
    "\n",
    "    model_ft = IDCM_NN(img_input_dim=input_data_par['img_dim'], text_input_dim=input_data_par['text_dim'], output_dim=input_data_par['num_class']).to(device)\n",
    "    params_to_update = list(model_ft.parameters())\n",
    "    optimizer = optim.Adam(params_to_update, lr=lr, betas=betas,weight_decay=weight_decay)\n",
    "    print('开始训练')\n",
    "    model_ft, img_acc_hist, txt_acc_hist, loss_hist = train_model(model_ft, data_loader, optimizer, alpha, beta,gamma,MAX_EPOCH)\n",
    "    print('训练完成')\n",
    "    print('在测试集评估')\n",
    "    view1_feature, view2_feature, view1_predict, view2_predict = model_ft(torch.tensor(input_data_par['img_test']).to(device), torch.tensor(input_data_par['text_test']).to(device))\n",
    "    label = torch.argmax(torch.tensor(input_data_par['label_test']), dim=1)\n",
    "    view1_feature = view1_feature.detach().cpu().numpy()\n",
    "    view2_feature = view2_feature.detach().cpu().numpy()\n",
    "    view1_predict = view1_predict.detach().cpu().numpy()\n",
    "    view2_predict = view2_predict.detach().cpu().numpy()\n",
    "    img_to_txt = fx_calc_map_label(view1_feature, view2_feature, label)\n",
    "    print('...Image to Text MAP = {}'.format(img_to_txt))\n",
    "\n",
    "    txt_to_img = fx_calc_map_label(view2_feature, view1_feature, label)\n",
    "    print('...Text to Image MAP = {}'.format(txt_to_img))\n",
    "\n",
    "    print('...Average MAP = {}'.format(((img_to_txt + txt_to_img) / 2.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
